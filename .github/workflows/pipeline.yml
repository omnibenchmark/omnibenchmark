name: CI Pipeline

concurrency:
  group: ${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

on:
  pull_request:

jobs:
  # Step 1: Run code style checks first
  lint:
    name: Code Style Check
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install Linters
        run: pip install ruff

      - name: Lint with Ruff
        continue-on-error: true
        run: |
          ruff check .

  # Step 2: Run tests only if linting passes
  tests:
    name: Run Tests
    needs: lint
    permissions: write-all
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ["3.12"]
        poetry-version: ["1.8.0"]
    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.os }}
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up python ${{ matrix.python-version }}
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Validate Poetry configuration
        run: poetry check

      - name: Load cached venv
        id: cached-dependencies
        uses: actions/cache@v4
        with:
          path: |
            .venv
          key: venv-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies with poetry
        if: steps.cached-dependencies.outputs.cache-hit != 'true'
        run: |
          poetry install --no-interaction --no-root --extras s3 --extras test

      - name: Install library
        run: poetry install --no-interaction

      - name: Run short tests
        run: |
          poetry run pytest -m short
        if: matrix.os == 'ubuntu-latest'

      # Build wheel after short tests pass
      - name: Build wheel
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12'
        run: |
          pip install build
          python -m build .

      # Upload the wheel as an artifact
      - name: Upload wheel artifact
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12'
        uses: actions/upload-artifact@v4
        with:
          name: omnibenchmark-wheel
          path: dist/*.whl
          retention-days: 7

      - name: Run longer tests (integration)
        run: |
          poetry run pytest -m "not short and not conda" --cov=omnibenchmark --cov-report=xml:./reports/coverage.xml \
              tests/benchmark tests/cli tests/workflow tests/io
        if: matrix.os == 'ubuntu-latest' || matrix.os == 'macos-latest'

      - name: Generate tests & coverage badges
        run: |
          poetry run genbadge tests -i ./reports/junit.xml -o ./reports/tests.svg
          poetry run genbadge coverage -i ./reports/coverage.xml -o ./reports/coverage.svg

      - if: ${{ matrix.os == 'ubuntu-latest' && matrix.python-version == '3.12' && matrix.poetry-version == '1.8.0' && github.event.pull_request.head.repo.full_name == github.repository }}
        name: Comment coverage result
        uses: MishaKav/pytest-coverage-comment@main
        with:
          pytest-xml-coverage-path: ./reports/coverage.xml

  # Step 3: Run software tests only if regular tests pass
  software-tests-linux:
    name: Software Tests (Linux)
    # XXX TODO: re-enable the dependency in the pipeline!
    # needs: tests
    needs: lint
    permissions: write-all
    strategy:
      matrix:
        os: [ubuntu-22.04]
        # test_group: [1, 2]
        python-version: ["3.12"]
      fail-fast: true

    runs-on: ${{ matrix.os }}
    container:
      image: ghcr.io/omnibenchmark/omnibenchmark-docker:main
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # test 2

      - name: Setup omnibenchmark environment
        uses: mamba-org/setup-micromamba@v1
        with:
          # environment-file: test-environment-${{ matrix.python-version }}.yml
          # XXX simplifying python version for now, stick to 3.12
          environment-file: test-environment.yml
          environment-name: omb
          cache-environment: false

      - name: Test Software Backends
        env:
          CI: true
        shell: bash -el {0}
        run: |
          pip install -e ".[s3]"
          pip install -e ".[test]"
          pip install numpy pandas scikit-learn scipy

          cd tests/software

          source "$LMOD_PKG"/init/profile

          export MODULEPATH="$HOME"/.local/easybuild/modules/all:"$GITHUB_WORKSPACE"/tests/data/envs
          module use $MODULEPATH

          module spider 3.6.3-foss-2017b

          export PYTHONPATH=${PYTHONPATH}:$LMOD_DIR/../init

          pytest -v -x --show-capture=stderr tests/software

        #--splits 2 --group ${{ matrix.test_group }} --splitting-algorithm=least_duration \
        #cli_conda_tests.py cli_singularity_tests.py cli_envmodules_tests.py \
        #conda_tests.py singularity_tests.py envmodules_tests.py test_run_with_software.py

  software-tests-mac:
    name: Software Tests (macOS)
    needs: tests
    permissions: write-all
    strategy:
      matrix:
        os: [macos-14]
        test_group: [1, 2]
        python-version: ["3.12"]
      fail-fast: false
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Homebrew
        id: set-up-homebrew
        uses: Homebrew/actions/setup-homebrew@master
        if: matrix.os == 'macos-14' || matrix.os == 'macos-13'

      - name: Install packages using homebrew
        shell: bash -el {0}
        run: |
          bash
          brew upgrade
          brew install coreutils
          brew install lmod
          brew install micromamba

      - name: Modify python version in test env
        shell: bash -el {0}
        run: |
          cp test-environment.yml test-environment-${{ matrix.python-version }}.yml
          sed -E 's/- conda-forge::python.+/- conda-forge::python =${{ matrix.python-version }}/' test-environment-${{ matrix.python-version }}.yml > tmp.yml
          mv tmp.yml test-environment-${{ matrix.python-version }}.yml

      - name: Manually create env
        shell: bash -el {0}
        run: |
          eval "$(micromamba shell hook --shell bash)"
          micromamba create -n omnibenchmark
          micromamba activate omnibenchmark
          micromamba install -f test-environment-${{ matrix.python-version }}.yml mamba=1

      - name: Modify bashrc
        env:
          CI: true
        shell: bash -el {0}
        run: |
          cat <<'EOF' >>~/.bashrc
          if [ -f /opt/homebrew/opt/lmod/init/bash ]; then
               source /opt/homebrew/opt/lmod/init/profile
          fi
          if [ -f /usr/local/opt/lmod/init/bash ]; then
               source /usr/local/opt/lmod/init/profile
          fi
          eval "$(micromamba shell hook --shell bash)"
          EOF

          cat <<'EOF' >>~/.bash_profile
          source ~/.bashrc
          EOF

      - name: Test
        env:
          CI: true
        shell: bash -el {0}
        run: |
          micromamba activate
          micromamba activate omnibenchmark

          pip install -e ".[s3]"
          pip install -e ".[test]"
          pip install numpy pandas scikit-learn scipy

          cd tests/software

          source "$LMOD_PKG"/init/profile

          export MODULEPATH="$HOME"/.local/easybuild/modules/all:"$GITHUB_WORKSPACE"/tests/data/envs
          module use $MODULEPATH

          export PYTHONPATH=${PYTHONPATH}:$LMOD_DIR/../init

          pytest -v -x --show-capture=stderr \
               --splits 2 --group ${{ matrix.test_group }} \
               conda_tests.py envmodules_tests.py cli_envmodules_tests.py cli_conda_tests.py test_run_with_software.py \
               -k 'not test_easybuild_sys_toolchain_build'

  # Step 4: Build documentation only if integration tests pass
  # TODO: also push to GitHub Pages only if documentation build is successful, and we're in a target branch.
